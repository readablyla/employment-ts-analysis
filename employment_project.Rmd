---
title: "Employment Analysis"
author: "Leala Darby, Scott Howard, Georgia Fardell"
date: "07/11/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
First load all required packages:
```{r message=FALSE, warning=FALSE}
library(car)
library(tseries)
library(astsa)
```

Load in the data:
```{r}
dat <- read.csv("employment_data.csv", fileEncoding = 'UTF-8-BOM')
head(dat)
```

Create a time series object from the data and plot. The blue lines are visually detected structural breakpoints - contextual reasoning is PC surge in the 90s and COVID-19. The red line indicates the training/test split. 
```{r}
ts_dat_test <- ts(dat[, 2], start = c(1978, 2), end = c(2020, 8), frequency = 12)
plot.ts(ts_dat_test, ylab="Employed (Persons)")
abline(v = 1993, col = "blue")
abline(v = 2020, col = "blue")
abline(v = 2019, col = "red", lty = 2)
```
Instructed to truncate data from January 1993 to December 2019 (inclusive)
```{r}
dat[dat$Observation.times == "Jan-93",]
dat[dat$Observation.times == "Dec-19",]
```
So we only need rows 180-503.
```{r}
trunc_dat <- dat[180:492,]
trunc_dat1 <- dat[180:503,]
ts_dat <- ts(trunc_dat[, 2], start = c(1993, 1), end = c(2018, 12), frequency = 12) #data for the modelling
ts_tot <- ts(trunc_dat1[, 2], start = c(1993, 1), end = c(2019, 12), frequency = 12) #total data for comparison
plot.ts(ts_dat)
plot.ts(diff(ts_dat)) # We are not actually taking the difference yet!
# This 2nd plot is just to help look for trends in variance. 
```
The trend in mean is readily observable.
Difficult to determine a trend in variance - there appears to be frequent changes, which are easier to see after incorporating lags of 1.
Check statistically for stationarity using the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test, which has the following hypotheses [...]:
```{r}
kpss.test(ts_dat)
```
The small p-value indicates that we should reject the null and conclude that the ts is not stationary.

As a rough test of constant variance (Levene's isn't really valid because time series data isn't independent)
```{r}
length(ts_dat)
Group <- c(rep(1,78), rep(2, 78), rep(3, 78), rep(4, 78))
leveneTest(ts_dat, Group)
```
The small p-value of $0.04837$ confirms that the data exhibits heteroscedasticity. Therefore we will perform a log transformation to attempt to reduce this:
```{r}
log_ts_dat <- log(ts_dat)
plot.ts(cbind(ts_dat, log_ts_dat))
leveneTest(log_ts_dat, Group)
```

At a significance level of 5%, the p-value above of 0.7209 provides very weak evidence and we fail to reject the null hypothesis of equal variance among groups. Thus the heteroscedasticity has been reduced.

Next, to reduce the trend in mean, apply differencing of 1 lag to our TS with stabilised variance:
```{r}
f_ts_dat <- diff(log_ts_dat, 1)
plot.ts(cbind(ts_dat, log_ts_dat, f_ts_dat))
```
To confirm constant mean and variance and a Gaussian distribution for the time series, a Shapiro-Wilk normality test is performed:
```{r}
hist(f_ts_dat)
shapiro.test(f_ts_dat)
```
The small p-value indicates likely non-normality, but this test isn't really valid for TS. Instead, check statistically for stationarity using the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test:
```{r}
kpss.test(log_ts_dat)
kpss.test(f_ts_dat)
```
The final ts has a high p-value of 0.1, which is statistically significant at a significance level of 5%. Therefore we fail to reject the null hypothesis, and have reasonable evidence that the final ts is stationary.

Next, the ACF and PACF of the differenced ts are plotted for analysis. 
```{r}
acf2(f_ts_dat)
```
Seasonal patterns in the ACF for TS_name (Figure [above]) show a slow decay in the dominant lags. To mitigate this, the time series was differenced in 12 lags giving [differenced model] for which the ACF and PACF are plotted in Figure [below].  
```{r}
ts_dat_12 <- diff(f_ts_dat, 12)
kpss.test(ts_dat_12) #Big enough to call stationary
acf2(ts_dat_12)
```

At the seasonal level, these indicate a cutoff at 1 in the ACF and tailing off in PACF, possibly indicating P=0 and Q=1. Lags 1,2,…,11 suggest several choices, so estimates of 0 ≤ p ≤ 1 and 0 ≤ q ≤ 1 are made and explored.  

```{r}
sarima(log_ts_dat, p = 1, d = 1, q = 1, P = 1, D = 1, Q = 1, S = 12) #AICc -8.123946
# ttable says ma1 coeff has highest p-value. removing this (model trimming):
sarima(log_ts_dat, p = 1, d = 1, q = 0, P = 1, D = 1, Q = 1, S = 12) #AICc -8.13055
# ttable says sar1 coeff has highest p-value. removing this:
sarima(log_ts_dat, p = 1, d = 1, q = 0, P = 0, D = 1, Q = 1, S = 12) #AICc -8.133259
```
By trimming coefficients and finding the minimum bias-corrected AIC, the model selected was $SARIMA(1,1,0)(0,1,1)_{12}$.

We see a couple of outliers - pinpoint what these points are. The Ljung-Box statistic is passable at lag 20 or 30.  



Fit the model from above with lowest AIC
```{r}
#fit1 <- sarima(log_ts_dat, p = 1, d = 1, q = 0, P = 0, D = 1, Q = 1, S = 12)
#sarima.for(log_ts_dat,12, 1,1,0, 0,1,1,12) from text book sarima.for
fit <- arima(log_ts_dat, c(1,1,0), seasonal = list(order = c(1,1,1), period = 12))
fore <- predict(fit, n.ahead = 12)
ts.plot(cbind(log_ts_dat, fore$pred),lwd = c(1,1), col = c(1,2), xlim = c(1993, 2020), ylab = "log_ts_dat", ylim = c(8.9, 9.5))
#lines(fore$pred, type="p", col=2)
lines(fore$pred + 2*fore$se, lty = "dashed", col = 4) #95% confidence boundaries 
lines(fore$pred - 2*fore$se, lty = "dashed", col = 4)
```

Try to put it over the whole data. need to undo the log
```{r}
ts.plot(cbind(ts_tot, exp(fore$pred)),lwd = c(1,1), col = c(1,2), xlim = c(1993, 2021), ylab = "original", ylim = c(7500, 13000) )
lines(fore$pred, type = "p", col = 2)
#lines(exp(fore$pred) + 2*exp(fore$se), lty = "dashed", col = 4) #95% confidence boundaries 
lines(exp(fore$pred+2*fore$se), lty="dashed", col=4)
#lines(exp(fore$pred) - 2*exp(fore$se), lty = "dashed", col = 4)
lines(exp(fore$pred-2*fore$se), lty="dashed", col=4)
#just order (of operations maybe) changed as per Prof's example
```



Try to graph just result section
```{r}
ts.plot(cbind(ts_tot, exp(fore$pred)),lwd = c(1,1), col = c(1,2), xlim = c(2018.5, 2020), ylab = "Employed (Persons)", ylim = c(12500, 13500) )
lines(fore$pred, type = "p", col = 2)
#95% confidence boundaries 
lines(exp(fore$pred+2*fore$se), lty="dashed", col=4)
lines(exp(fore$pred-2*fore$se), lty="dashed", col=4)
```


Assess the predictions.

Discuss future work.
